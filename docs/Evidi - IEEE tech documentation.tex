\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{array}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{svg}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\DefineVerbatimEnvironment{CodeBlock}{Verbatim}{
    fontsize=\footnotesize,
    breaklines=true,
    frame=single,
    framesep=2mm
}
    
\begin{document}
\title{Evidi\\ \vspace{0.5 cm} \small \textit{Web based AI-powered assistant for sourcing, filtering and summarizing job offers.}\\}

\author{
\IEEEauthorblockN{ROBIN, Héloïse}
\IEEEauthorblockA{\textit{Dept. Computer Science}\\
\textit{Hanyang University}\\
Seoul, S. Korea \\
heloiserobin@hanyang.ac.kr}
\and
\IEEEauthorblockN{KHEYAR¸ Adel}
\IEEEauthorblockA{\textit{Dept. Computer Science}\\
\textit{Hanyang University}\\
Seoul, S. Korea \\
adelkheyar@hanyang.ac.kr}
\and
\IEEEauthorblockN{ARM, Jules}
\IEEEauthorblockA{\textit{Dept. Computer Science}\\
\textit{Hanyang University}\\
Seoul, S. Korea \\
julesarm@hanyang.ac.kr}
\and
\IEEEauthorblockN{DESJONQUERES, Nicolas}
\IEEEauthorblockA{\textit{Dept. Computer Science}\\
\textit{Hanyang University}\\
Seoul, S. Korea \\
nicolasdesjonqueres@hanyang.ac.kr}
}

\maketitle

\begin{abstract}
The \textbf{Evidi Job Response Assistant} is a webapp that aims to streamline the job application process through automation with artificial intelligence. In the current employment landscape, job seekers face the repetitive task of manually searching, reviewing, and responding to numerous job offers across multiple platforms. This project proposes an automated workflow capable of retrieving job offers from multiple sources, filtering them based on personalized user criteria, giving an AI-generated match score and feedback, summarizing descriptions using language models, and generating a draft for a cover letter.

The proposed solution's tech stack is as follows: FastAPI serves as the backend API, MongoDB Atlas as the cloud database, n8n for the AI-driven workflows, and React + TypeScript as the frontend UI. In addition, the project leverages Gemini's API for filter extraction, job offer matching, and content creation (AI summaries, cover letters). The app is deployed entirely in the cloud with Vercel for the frontend + backend, and Railway for hosting the n8n workflows.
\end{abstract}

\begin{IEEEkeywords}
Job search, Artificial Intelligence, Automated workflows, FastAPI, n8n, MongoDB Atlas, React, Vercel, Railway, Natural Language Processing
\end{IEEEkeywords}

\section{Role Assignments}

\begin{table}[htpb]
\caption{Role Assignments}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{1.6cm}|>{\centering\arraybackslash}m{1.6cm}|m{4.2cm}|}
\hline
\textbf{Role} & \textbf{Name} & \textbf{Task Description} \\
\hline
User & Jules & Use the app as a real user. Provide feedback on its use of the app. Report bugs, and suggest improvements. \\
\hline
Customer & Adel & Provide requirements and feedback. Validate the functional design and user experience. Evaluate deliverables during milestones (UI mockups, MVP demo). Ensure the project meets academic or business goals. \\
\hline
Frontend developer & Nicolas \& Héloïse & Implement frontend in React (UI, API calls). Develop backend API. Design and integrate the database (MongoDB Atlas). Configure n8n workflows for automation and AI processing. Test, debug, and deploy components on cloud platforms. \\
\hline
Development Manager & Héloïse & Define project scope, timeline, and milestones. Assign tasks to team members and manage version control on GitHub. Supervise testing, deployment, and documentation.\\
\hline
\end{tabular}
\end{center}
\end{table}


%---------- INTRO SECTION

\section{Introduction}

\subsection{Motivation}
In today's world, the process of job seeking has evolved into an increasingly complex and repetitive task. As students actively searching for internships and experiencing the process firsthand, we have encountered various forms of mental fatigue and stress stemming from these challenges. Candidates are now required to navigate a growing number of job platforms, manage many applications to secure a single interview opportunity, and adapt to ever-longer and more intricate recruitment processes. 

Because of this, job seekers have to spend more and more time reviewing postings, extracting relevant qualifications, and tailoring application materials for each opportunity. Over time, these repetitive actions contribute to demotivation, reduced efficiency, and even missed opportunities. At the same time, organizations receive vast volumes of generic or mismatched applications, revealing a structural imbalance and inefficiency in the modern recruitment system.

With the rapid progress in Artificial Intelligence (AI), particularly in workflow automation, a unique opportunity arises to reimagine this whole process. Automating the collection, analysis, and filtering of job offers can significantly reduce the burden placed on applicants while improving the relevance and quality of submissions. Such an approach not only streamlines the job search but also promotes more equitable and intelligent access to employment information. The motivation behind this work is therefore to develop a transparent, modular, and accessible tool that leverages automation ethically and effectively, supporting individuals throughout their job search journey and alleviating the cognitive load inherent to current recruitment processes.

\subsection{Problem Statement (User Needs)}
Despite the apparent convenience of existing online job boards such as \textbf{LinkedIn}, \textbf{Glassdoor}, or \textbf{Indeed}, users continue to face several persistent pain points. These platforms provide keyword filters and automated alerts, yet they remain fundamentally passive, offering limited personalization and no actionable feedback. Users must still sift through each posting, interpret nuanced requirements, and manually prepare application materials.

Automation services like \textbf{Zapier} or \textbf{Make (Integromat)} enable general workflow integration, but they are not tailored to employment-specific scenarios and require prior technical knowledge to build effective workflows. They lack semantic understanding of job-related data, resulting in rigid automation pipelines. Moreover, while advanced AI systems such as \textbf{ChatGPT} can generate natural language content, they still demand extensive prompting and lack integration with dynamic job feeds or structured filtering mechanisms.

From an educational and research standpoint, this absence of a unified, open, and domain-specific framework poses a challenge for practitioners and students seeking to explore AI-driven automation in realistic settings. Therefore, there is a clear need for a customizable, intelligent, and transparent ecosystem that unifies job data retrieval, summarization, and response generation within a single, cloud-ready platform.

\subsection{Existing Solutions}
A comparative analysis of current tools reveals several partial solutions, yet none fully address the multidimensional needs of job seekers.  

Platforms such as \textbf{Simplify} and \textbf{LoopCV} attempt to streamline the application process by automating repetitive form-filling or submission tasks. However, their infrastructures are proprietary and non-extensible, limiting opportunities for customization or academic exploration. Similarly, \textbf{Huntr} provides efficient tracking for ongoing applications but lacks an AI-driven decision layer capable of analyzing or ranking offers intelligently.  

On the other hand, low-code automation platforms such as \textbf{Zapier} and \textbf{n8n} allow users to design workflows visually, connecting data sources and web APIs. While powerful, they operate as generic middleware and do not incorporate domain-specific heuristics such as keyword extraction, offer classification, or motivation-letter personalization. Finally, AI-driven assistants like \textbf{ChatGPT} or \textbf{Claude} can generate text upon request but cannot autonomously interact with job data sources or maintain persistent user contexts across sessions.  

This review highlights the fragmented nature of current technological ecosystems and underscores the necessity of an integrated, open-source framework where AI models, automation logic, and user interfaces converge seamlessly.

\subsection{Proposed Solution}
The \textbf{Evidi Job Response Assistant} is designed to address these gaps by combining the flexibility of modern cloud computing with the intelligence of advanced language models. The proposed system features a modular architecture comprising four key layers: \textbf{data ingestion}, \textbf{AI-driven processing}, \textbf{backend management}, and \textbf{interactive visualization}.  

Through \textbf{n8n}, the system automatically retrieves job offers from diverse sources such as RSS feeds, email inboxes, and public APIs. These offers are then filtered through user-defined criteria (including domain, skills, or salary range) and stored in a \textbf{MongoDB Atlas} database managed via a \textbf{FastAPI} backend. The backend exposes RESTful endpoints that feed into a \textbf{React + TypeScript} frontend, where users can visualize offers, summaries, and application drafts.  

An \textbf{AI layer}, powered by \textbf{OpenAI GPT-4}, performs advanced summarization and generates personalized application responses. The combination of these technologies results in a robust workflow that minimizes manual intervention, enhances precision, and supports reproducible research. Beyond its technical contributions, this project aims to demonstrate a scalable model for \textbf{AI-assisted decision-making} and to provide an educational reference for integrating automation, data engineering, and language intelligence in real-world employment contexts.




%---------- REQUIREMENTS


\section{Requirements}

\subsection{User session management}

\noindent
The system must provide secure and user-friendly mechanisms for registration, authentication, and session management.

\begin{itemize}
    \item \textbf{Registration:}  
    New users must create an account using a valid email address and password. Upon submission, an email verification code is sent automatically. Only verified accounts gain access to the main interface.
    
    \item \textbf{Password Security:}  
    All user passwords are hashed using a robust cryptographic algorithm (e.g., \textbf{SHA-256} or \textbf{bcrypt}) prior to database storage. Plaintext passwords are never stored or transmitted.
    
    \item \textbf{Login:}  
    The login process validates the provided credentials against stored hash values. Upon success, a \textbf{JWT (JSON Web Token)} is issued to manage authenticated sessions securely across the frontend and backend.
    
    \item \textbf{Account Recovery:}  
    In case of forgotten credentials, the system provides a password reset flow via email-based verification. Expired or invalid tokens are automatically rejected to maintain security.
\end{itemize}

\subsection{User Criteria Management}

\noindent
Users can define personalized job search criteria that guide the system’s filtering and retrieval mechanisms.

\begin{itemize}
    \item \textbf{Criteria Creation:}  
    Users specify parameters such as target keywords, job titles, industries, required skills, employment type (e.g., remote, full-time, internship), and geographic location.
    
    \item \textbf{Criteria Persistence:}  
    Each user’s preferences are stored in the cloud database under a unique user identifier, allowing the same filters to be reused automatically for subsequent job searches.
    
    \item \textbf{Dynamic Modification:}  
    The user interface enables modification or deletion of existing criteria. Any change triggers an immediate synchronization across the backend and automation workflows.
    
    \item \textbf{Validation:}  
    Input validation ensures the accuracy of filter definitions, preventing empty or malformed entries before committing data to storage.
\end{itemize}

\subsection{Job Offer Ingestion System}

\noindent
The ingestion module is responsible for automatically collecting job offers from multiple external sources in a structured and scalable manner.

\begin{itemize}
    \item \textbf{Sources of Data:}  
    The system supports several channels:
    \begin{itemize}
        \item RSS feeds from public job boards.
        \item REST APIs from professional platforms (e.g., LinkedIn, Indeed, Welcome to the Jungle).
        \item Email inbox parsing for newsletters and subscriptions.
    \end{itemize}
    
    \item \textbf{Automation Pipeline:}  
    Workflows are executed through the \textbf{n8n} automation platform. Each workflow consists of nodes for fetching, transforming, and forwarding job data to the backend.
    
    \item \textbf{Data Standardization:}  
    Collected job data is normalized into a unified JSON structure with standardized fields such as \texttt{title}, \texttt{company}, \texttt{location}, \texttt{skills}, \texttt{description}, and \texttt{source}.
    
    \item \textbf{Scheduling:}  
    The ingestion process operates at configurable intervals (e.g., every 2 hours) or can be triggered manually by the user through the frontend.
\end{itemize}

\subsection{Offer Filtering Module}

\noindent
Once data is ingested, the filtering module compares each offer against the user’s criteria to identify relevant matches.

\begin{itemize}
    \item \textbf{Matching Algorithm:}  
    A hybrid approach combining keyword search and semantic similarity (e.g., cosine similarity via sentence embeddings) determines the relevance of each offer.
    
    \item \textbf{Scoring System:}  
    Each offer receives a numerical relevance score between 0 and 1. Only offers above a user-defined threshold (e.g., 0.7) are retained for summarization.
    
    \item \textbf{Duplicate Detection:}  
    Hash-based identifiers prevent repeated storage of identical job listings from multiple sources.
    
    \item \textbf{Result Storage:}  
    Filtered offers are saved in the MongoDB database and marked with their corresponding user ID, timestamp, and relevance score.
\end{itemize}

\subsection{AI Summarization Engine}

\noindent
The summarization engine leverages \textbf{OpenAI GPT-4} to generate concise and structured job summaries.

\begin{itemize}
    \item \textbf{Input Data:}  
    The engine receives the normalized job description text and associated metadata from the filtering module.
    
    \item \textbf{Prompt Template:}  
    A predefined template guides the model to produce summaries containing the following sections:  
    \textit{Position Title, Company Overview, Key Responsibilities, Required Skills, and Application Insights.}
    
    \item \textbf{Output Format:}  
    Summaries are returned as structured text blocks and stored alongside the original job offers in the database.
    
    \item \textbf{Quality Control:}  
    The backend verifies that all expected fields are present before saving the result. In case of missing or malformed output, a re-generation is automatically triggered.
\end{itemize}

\subsection{AI Letter Draft Generation (Optional)}

\noindent
An optional functionality enables users to generate personalized cover letter drafts for selected job offers.

\begin{itemize}
    \item \textbf{Input Context:}  
    The model combines three sources of information:  
    (1) the summarized job offer,  
    (2) the user’s stored profile data,  
    (3) previously defined motivation style preferences.
    
    \item \textbf{Prompt Structure:}  
    The AI is instructed to generate a professional and context-aware letter draft with three sections: introduction, motivation, and conclusion.
    
    \item \textbf{User Review:}  
    Generated letters are displayed in the frontend editor, allowing the user to modify, approve, or export them in text or PDF format.
\end{itemize}

\subsection{Data Management Layer}

\noindent
All information produced by the system (job offers, summaries, and user data) is stored and managed within a secure cloud database.

\begin{itemize}
    \item \textbf{Database Engine:}  
    The system uses \textbf{MongoDB Atlas}, chosen for its scalability, flexibility, and document-based structure that fits dynamic job data.
    
    \item \textbf{Data Schema:}  
    Each document includes nested structures for offer metadata, AI-generated summaries, and associated user identifiers.
    
    \item \textbf{Backup and Retention:}  
    Automatic backup policies ensure data persistence. Obsolete or expired job offers are archived to a secondary collection for future analysis.
\end{itemize}

\subsection{Notification and Alert System}

\noindent
To enhance user engagement, the system automatically informs users of new or relevant job opportunities.

\begin{itemize}
    \item \textbf{Notification Triggers:}  
    Alerts are generated whenever a newly ingested job offer exceeds the user’s relevance threshold.
    
    \item \textbf{Delivery Channels:}  
    Notifications are dispatched through email or third-party integrations such as Slack or Telegram via \textbf{n8n} connectors.
    
    \item \textbf{Content Format:}  
    Each notification includes the job title, company name, and a short excerpt of the AI summary with a link to view full details on the dashboard.
\end{itemize}

\subsection{Frontend Visualization Dashboard}

\noindent
The user interface provides access to all system functionalities in an organized and interactive manner.

\begin{itemize}
    \item \textbf{Technology Stack:}  
    Developed using \textbf{React} and \textbf{TypeScript}, ensuring responsiveness, modularity, and cross-platform accessibility.
    
    \item \textbf{Views and Components:}  
    The dashboard consists of multiple pages: login, profile settings, job feed, AI summaries, and letter drafts.
    
    \item \textbf{Interaction Design:}  
    Users can filter, search, and sort offers; review AI-generated content; and trigger workflow actions directly (e.g., “generate letter” or “refresh offers”).
\end{itemize}

\subsection{System Integration Workflow}

\noindent
This component defines the interaction model between all subsystems of the platform, ensuring reliable communication across the automation layer, backend, database, and frontend.

\begin{itemize}
    \item \textbf{Backend API:}  
    Implemented with \textbf{FastAPI}, the backend exposes RESTful endpoints for job data retrieval, filtering operations, and AI-driven processing through the Gemini API.

    \item \textbf{Authentication Flow:}  
    Communication between the frontend and backend is secured using JWT-based authentication, ensuring protected access to user-specific functionalities.

    \item \textbf{Automation Orchestration:}  
    \textbf{n8n} workflows, hosted on Railway, periodically fetch and preprocess external job data sources before synchronizing them with the backend database, maintaining up-to-date listings.

    \item \textbf{Deployment Infrastructure:}  
    The frontend and backend are deployed on \textbf{Vercel}, offering automated builds and global edge delivery. Automation workflows run on \textbf{Railway}, while persistent data storage is managed through \textbf{MongoDB Atlas}.
\end{itemize}





%---------- DEV ENV

\section{Development Environment}


\subsection{Choice of Software Development Platform}

The \textbf{Evidi Job Response Assistant} is developed as a distributed, cloud-based web application that integrates automation, AI, and workflow orchestration.
The project aims to streamline the job search process by automating the retrieval, filtering, and summarization of job offers through AI-driven methods.
Given the short project timeline (two months) and the requirement for a scalable, low-maintenance architecture, we selected a modern and cloud-native technology stack.

The backend is implemented in Python using \textbf{FastAPI}, chosen for its simplicity, performance, and native support for asynchronous operations. The database layer relies on \textbf{MongoDB Atlas}, a cloud-based NoSQL solution well suited for handling unstructured text data such as job descriptions. The automation component is powered by \textbf{n8n}, which provides a visual workflow environment to connect APIs and automate data ingestion tasks. The frontend is built with \textbf{React} and \textbf{TypeScript}, with UI prototyping conducted using \textbf{Figma}'s AI-assisted design tools. The system's intelligence layer uses \textbf{Gemini}'s API to perform match scoring, job summarization, and draft letter generation.

For deployment, both the backend and frontend are hosted on \textbf{Vercel}, selected for its streamlined developer experience and efficient debugging capabilities. The automation workflows are deployed on \textbf{Railway}, which also provides the necessary database resources required for operating \textbf{n8n}.

This configuration provides a balance between scalability, modularity, and ease of collaboration among our team.

\begin{table}[htpb]
\caption{Tools and Language Choice}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{2.4cm}|m{5.2cm}|}
\hline
\textbf{Tools and Language} & \textbf{Reason} \\
\hline
\textbf{FastAPI (Python)} & FastAPI is a modern, high-performance Python framework optimized for building APIs. Its ASGI-based asynchronous support enables efficient handling of concurrent requests, which is essential for AI summarization calls and webhook-based integrations. Built-in OpenAPI generation, Pydantic validation, and type safety contribute to a robust and maintainable backend. \\
\hline
\textbf{MongoDB Atlas} & MongoDB Atlas provides a fully managed, cloud-hosted NoSQL database ideal for dynamic and semi-structured data such as job listings. Its flexible document model allows variable fields without strict schemas. The service offers high availability, effortless scalability, and seamless integration with Python, reducing infrastructure maintenance overhead. \\
\hline
\textbf{n8n} & n8n offers a visual, low-code automation platform capable of orchestrating workflows across APIs, databases, and AI services. It automates RSS ingestion, filtering, and forwarding logic to the backend, significantly reducing custom scripting. Its cloud-friendly deployment and transparency make it accessible to both technical and non-technical contributors. \\
\hline
\textbf{React + TypeScript} & React provides a modular, component-based architecture for building responsive and dynamic user interfaces. TypeScript adds static type checking, improving reliability and reducing runtime errors. This combination accelerates frontend development while ensuring maintainability and smooth integration with backend services. \\
\hline
\textbf{Gemini API} & The Gemini API delivers advanced natural language processing capabilities for filter extraction, summarization, match scoring, and cover letter draft generation. It enables efficient transformation of long job descriptions into concise outputs and supports scalable experimentation through prompt engineering in an API-first architecture. \\
\hline
\textbf{Vercel + Railway} & Vercel offers seamless deployment and continuous integration for both the backend and frontend, providing a unified developer experience and efficient debugging environment. Railway hosts the automation workflows and provides the database resources required for operating \textbf{n8n}, ensuring reliable background job execution. \\
\hline
\end{tabular}
\end{center}
\end{table}


\vspace{1 cm}

\subsection{Cost Estimation}

Ensuring the reliability and scalability of the \textbf{Evidi Job Response Assistant} requires cloud services that minimize operational overhead while providing sufficient performance.
We selected free-tier and low-cost cloud options to maintain budget efficiency during the prototype phase while retaining professional-grade capabilities.

\textbf{Vercel} provides free-tier hosting for both the FastAPI backend and the React frontend, supporting continuous deployment, SSL-secured endpoints, and seamless integration with GitHub.
Workflow automation and background tasks are deployed on \textbf{Railway}, whose cheapest plan (approximately 0.40 USD per day) offers persistent execution and the infrastructure required for running \textbf{n8n}.
For data storage, \textbf{MongoDB Atlas}’s M0 cluster tier supports several thousand job entries at no cost, offering built-in backups and high availability.

API-driven intelligence is powered by the \textbf{Gemini} free plan, which provides sufficient quota for summarization, match scoring, and draft generation during development without incurring usage fees.

Overall operational costs remain minimal. The only recurring expense is the \textbf{Railway} plan, amounting to roughly 12 USD per month, keeping the total cost low while ensuring reliable cloud-based operation of the system.

\begin{table}[htpb]
\caption{Hosting and AI Tools}
\begin{center}
\begin{tabular}{|>{\centering\arraybackslash}m{2.4cm}|m{5.2cm}|}
\hline
\textbf{Tools and Services} & \textbf{Reason} \\
\hline
\textbf{Vercel (Backend \& Frontend Hosting)} & Vercel provides a unified platform for hosting both the FastAPI backend and the React frontend. Its automated CI/CD pipelines, global edge network, and built-in HTTPS support enable seamless deployment and rapid iteration without server management. \\
\hline
\textbf{Railway (Automation Hosting)} & Railway hosts the \textbf{n8n} workflows used for automation and data ingestion. Its low-cost plan (≈0.40 USD/day) offers persistent execution, easy scaling, and integrated resource provisioning, making it suitable for handling recurring background tasks. \\
\hline
\textbf{MongoDB Atlas (Database Hosting)} & MongoDB Atlas’s M0 free-tier cluster provides a fully managed NoSQL database with automated backups, monitoring, and high availability. It is well suited for storing unstructured job listings and requires no local infrastructure. \\
\hline
\textbf{Gemini API (AI Processing)} & The Gemini API delivers advanced natural language processing capabilities for summarization, match scoring, and draft letter generation. The free plan offers sufficient quota for prototype-level workloads without introducing additional operational costs. \\
\hline
\end{tabular}
\end{center}
\end{table}



\subsection{Software in Use}

\subsubsection{Existing Systems / Tools} 

\textbf{\\Simplify (Simplify Copilot)} is a browser-based tool that automates repetitive job application tasks. It provides features such as auto-filling application fields, tracking applications, tailoring resumes, and identifying missing keywords in one’s CV. 
While Simplify excels at streamlining the manual data entry portion of applications, it does not (publicly) provide a unified backend, cross-source ingestion pipeline, or AI summarization embedded in a web app.

\textbf{LoopCV} is another job search automation platform that matches job seekers with listings and automates part of the application process. It uses AI to optimize CVs, track applications, and even directly apply on behalf of the user.   
LoopCV’s strength lies in its end-to-end workflow (search → apply → track), but it is a closed, commercial product with limited transparency into its internal pipelines.

\textbf{Huntr} offers features for job application tracking, AI-assisted resume and cover letter generation, and auto-filling application forms.   
However, Huntr is primarily a productivity / tracking tool; it does not appear to automate ingestion from RSS or provide full workflow orchestration with external services like n8n.

\textbf{LazyApply} automates job applications across job platforms via AI, handling form filling and submission. 
Its value is in applying at scale, but challenges include handling custom fields, CAPTCHA, and job boards with complex forms.

From the research perspective, \textbf{ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement} introduces a pipeline that takes job descriptions and resumes and produces tailored, optimized CVs using LLMs. 
This aligns with our AI-driven summary / draft generation module. It demonstrates the viability of leveraging LLMs for alignment between job descriptions and user profiles.

\subsubsection{Comparison \& Gap Analysis}

\begin{itemize}
  \item \textbf{Scope of ingestion:} Existing tools like Simplify or LazyApply typically rely on browser extension or manual input, whereas our project plans to support ingestion via RSS feeds, APIs, and emails through automation workflows.
  \item \textbf{AI summarization / drafting:} While tools offer resume optimization or cover letter suggestions, few expose summarization of full job descriptions or draft generation from user profile + job content. Our approach explicitly integrates that.
  \item \textbf{Transparency and extensibility:} Commercial tools are black-box; you cannot inspect or customize their pipelines. We provide modular architecture (n8n + API backend) that is open, testable, and extensible.
  \item \textbf{Integration \& orchestration:} Our system orchestrates ingestion, filtering, AI processing, and persistence together. Tools like Simplify partly automate, but lack seamless end-to-end pipeline control integrated with a web app interface.
  \item \textbf{Flexibility \& deployment:} Because ours relies on open stack (FastAPI, MongoDB, n8n, React), we can adapt features, scale, modify workflows, or replace components, which is typically impossible with off-the-shelf tools.
\end{itemize}

% \subsection{Task Distribution}

%---------- SPECS

\section{Specifications}
\subsection{Requirement 1 – User Management}

\textbf{Goal:} Allow users to register, authenticate, and manage their profile and preferences.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Frontend:} Login and Register pages with full name, email, password, and confirmation fields. Settings page for profile update, password change, and notification preferences. Axios handles communication with backend.
    \item \textbf{Backend:} FastAPI endpoints \texttt{/register}, \texttt{/login}, \texttt{/user/preferences}, \texttt{/user/profile}, and \texttt{/user/password}. JWT-based authentication and bcrypt password hashing.
    \item \textbf{Database:} MongoDB collection \texttt{users} storing \texttt{\{ \_id, full\_name, email, password\_hash, preferences, settings \}}.
    \item \textbf{Security:} JWT tokens for authentication, password validation, and session protection.
\end{itemize}

\textbf{Pseudocode:}
% \begin{verbatim}
% POST /register:
%   receive {full_name, email, password}
%   hash = bcrypt.hash(password)
%   insert into db.users({full_name, email, hash})
%   return success

% POST /login:
%   check email exists
%   verify bcrypt(password, hash)
%   return JWT_token
% \end{verbatim}

\begin{CodeBlock}
POST /register:
  receive {full_name, email, password}
  hash = bcrypt.hash(password)
  insert into db.users({full_name, email, hash})
  return success

POST /login:
  check email exists
  verify bcrypt(password, hash)
  return JWT_token
\end{CodeBlock}

\subsection{Requirement 2 – Criteria \& Filter Management}

\textbf{Goal:} Allow users to define, update, and store job search preferences.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Frontend:} Filters page with tech stack tags, experience level, include/exclude keywords, location preferences, and job type options.
    \item \textbf{Backend:} FastAPI endpoints \texttt{/criteria/update} and \texttt{/criteria/get}.
    \item \textbf{Database:} MongoDB collection \texttt{criteria} linked to user ID.
    \item \textbf{Integration:} n8n workflows retrieve criteria for dynamic filtering.
\end{itemize}

\textbf{Pseudocode:\\}
\begin{CodeBlock}
POST /criteria/update:
  user_id = JWT_token.user
  update db.criteria where user_id
  return success
\end{CodeBlock}

\subsection{Requirement 3 – Job Offer Ingestion}

\textbf{Goal:} Retrieve and store job offers automatically from public and integrated sources.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Automation:} n8n workflows scheduled every 3 hours to fetch from RSS feeds, APIs, or email triggers.
    \item \textbf{Backend:} FastAPI webhook \texttt{/webhook/jobs} receives job payloads and stores them in MongoDB.
    \item \textbf{Frontend:} Sources page to add, edit, or remove sources with manual sync and status indicators.
\end{itemize}

\textbf{Pseudocode:\\}
\begin{CodeBlock}
RSS Trigger -> Filter (new posts only)
-> HTTP POST to FastAPI /webhook/jobs
-> Insert into db.jobs
\end{CodeBlock}

\subsection{Requirement 4 – Offer Filtering}

\textbf{Goal:} Match job offers against user-defined criteria.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{n8n:} “IF” nodes filter job payloads based on keywords and location.
    \item \textbf{Backend:} Python regex fallback for keyword matching.
    \item \textbf{Frontend:} Jobs page filter dropdown (All, Matched, Applied, Rejected) with match badges.
\end{itemize}

\textbf{Pseudocode:\\}
\begin{CodeBlock}
for job in new_jobs:
  if any(keyword in job.description for keyword in 
  user.criteria):
    insert into db.jobs_filtered
\end{CodeBlock}

\subsection{Requirement 5 – AI Summarization}

\textbf{Goal:} Generate concise AI summaries for each job description.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{n8n:} HTTP request node calls OpenAI API (GPT-4/4o-mini).
    \item \textbf{Backend:} FastAPI endpoint \texttt{/ai/summarize} for manual trigger.
    \item \textbf{Frontend:} Job Detail Modal’s “AI Summary” tab shows results with regeneration option.
    \item \textbf{Database:} MongoDB collection \texttt{summaries}.
\end{itemize}

\textbf{Pseudocode:\\}
\begin{CodeBlock}
POST /ai/summarize:
  input = job.description
  prompt = "Summarize in 5 bullet points"
  response = openai.ChatCompletion(prompt)
  db.summaries.insert({job_id, summary: response})
\end{CodeBlock}

\subsection{Requirement 6 – AI Letter Draft Generation}

\textbf{Goal:} Automatically generate a motivation letter based on user’s CV and job description.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{n8n:} Uses OpenAI API with user profile and job data.
    \item \textbf{Backend:} Endpoint \texttt{/ai/draft} for manual regeneration.
    \item \textbf{Frontend:} “Cover Letter” tab in Job Detail Modal with edit, regenerate, copy, and download options.
\end{itemize}

\textbf{Prompt Example:\\}
\begin{CodeBlock}
"Write a short motivation paragraph for 
this position based on user’s experience 
and the job description."
\end{CodeBlock}

\subsection{Requirement 7 – CV Upload \& Analysis}

\textbf{Goal:} Analyze uploaded CVs to extract skills and job preferences.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Frontend:} CV Analysis page with drag-and-drop upload, file card, and AI analysis results.
    \item \textbf{Backend:} Endpoint \texttt{/cv/analyze} using OpenAI model for extraction.
    \item \textbf{Database:} Stores extracted skills, experience level, and preferences in \texttt{cv\_analysis} collection.
\end{itemize}

\textbf{Workflow:\\}
\begin{CodeBlock}
Upload CV -> Analyze with AI -> Extract 
Skills and Preferences -> Store in db.cv_analysis 
-> Apply to Filters
\end{CodeBlock}

\subsection{Requirement 8 – Notification System}

\textbf{Goal:} Notify users of new job matches via multiple channels.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{n8n:} Slack, Email, or Push notification nodes.
    \item \textbf{Backend:} Endpoint \texttt{/api/notify} for message dispatching.
    \item \textbf{Frontend:} Settings page toggles for email, push, and weekly digest.
\end{itemize}

\textbf{Message Example:\\}
\begin{CodeBlock}
"New job matching your skills: Data Engineer at 
XCorp."
\end{CodeBlock}

\subsection{Requirement 9 – Dashboard \& Analytics}

\textbf{Goal:} Display user’s job search metrics and activity overview.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Frontend:} Dashboard with stats cards (Total Jobs, Matched, Applied, Response Rate), recent activity feed, and quick actions.
    \item \textbf{Backend:} Endpoint \texttt{/api/dashboard} aggregates metrics.
    \item \textbf{Database:} Activity logs stored for history display.
\end{itemize}

\subsection{Requirement 10 – Frontend Dashboard and Navigation}

\textbf{Goal:} Provide a modern, responsive interface for all application modules.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Framework:} React + TypeScript + Tailwind CSS.
    \item \textbf{Global UI:} Header with logo, theme switcher, settings, logout.
    \item \textbf{Navigation:} Tabs for Dashboard, Jobs, Sources, Filters, CV Analysis, and Settings.
    \item \textbf{Theme Support:} Default, Dark, Deep Blue, and Green themes.
\end{itemize}

\subsection{Requirement 11 – Data Storage}

\textbf{Goal:} Securely persist all user and job-related data.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Database:} MongoDB collections for users, criteria, jobs, summaries, letters, CV analyses, and notifications.
    \item \textbf{Access Control:} JWT authentication required for all write operations.
\end{itemize}

\textbf{Schema:\\}
\begin{CodeBlock}
users: { _id, full_name, email, 
password_hash, preferences, settings }
criteria: { user_id, tech_stack[], 
keywords_include[], keywords_exclude[], 
location[], job_type[], experience_level[] }
jobs: { job_id, title, company, description, 
tags[], location, source, matched }
summaries: { job_id, summary, ai_model, 
updated_at }
letters: { job_id, user_id, content, updated_at }
cv_analysis: { user_id, extracted_skills[], 
experience_level, preferences }
notifications: { user_id, message, type, 
timestamp, read }
\end{CodeBlock}

\subsection{Requirement 12 – Logging, Monitoring \& Error Handling}

\textbf{Goal:} Ensure observability, traceability, and efficient debugging across all components of the system.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{FastAPI:} Request/response logging handled through middleware, including timestamps and status codes. Exceptions are captured via FastAPI's global error handler for structured output.
    \item \textbf{n8n (Railway):} Built-in workflow execution logs, node-level error traces, and retry policies for failed tasks.
    \item \textbf{Cloud Hosting (Vercel \& Railway):} Vercel provides real-time logs for backend and frontend deployments, including build diagnostics and runtime errors. Railway logs workflow execution events, webhook calls, and system-level failures.
    \item \textbf{Frontend:} Browser-side error boundaries, toast notifications, and retry mechanisms handle user-facing failures and network instability.
\end{itemize}


\subsection{Requirement 13 – Testing and Validation}

\textbf{Goal:} Ensure application stability through automated testing.

\textbf{Implementation:}
\begin{itemize}
    \item \textbf{Backend:} Pytest for unit testing and Postman for integration tests.
    \item \textbf{Frontend:} React Testing Library for component testing.
    \item \textbf{Automation:} GitHub Actions CI pipeline for continuous testing.
\end{itemize}

\subsection{Requirement 14 – Integration Workflow}

\textbf{Goal:} Maintain full interoperability among system components.

\textbf{Architecture Overview:}
\begin{itemize}
    \item \textbf{n8n:} Manages ingestion, filtering, and AI summarization.
    \item \textbf{FastAPI:} Handles authentication, validation, and persistence.
    \item \textbf{MongoDB:} Centralized data storage.
    \item \textbf{OpenAI API:} Provides summarization and letter generation.
    \item \textbf{React Frontend:} Displays user-facing data and controls.
\end{itemize}

\textbf{Data Flow:\\}
\begin{CodeBlock}
[RSS / API / Email Source]
        ↓
    [n8n Workflow]
        ↓
 [AI Summarizer Node / Letter Draft Node]
        ↓
 [FastAPI Webhooks (/webhook/jobs, /ai/...)]
        ↓
       [MongoDB]
        ↓
 [React Frontend Dashboard & Pages]
\end{CodeBlock}

\subsection{Requirement 15 – UX Enhancements (Cross-Page Features)}

\textbf{Goal:} Enhance user experience through modern interaction patterns.

\textbf{Implementation:}
\begin{itemize}
    \item Toast notifications for success, error, and info messages.
    \item Loading indicators, skeleton loaders, and progress feedback.
    \item Responsive mobile design with touch-friendly inputs.
    \item Keyboard accessibility for modals and navigation.
    \item Smooth theme transitions and persistent preferences.
\end{itemize}

\section{Architecture Design \& Implementation}

This section presents the architectural structure of the Evidi system, with a focus on its modular decomposition and implementation strategy. Each module is described in detail, including its purpose, responsibilities, internal components, and reasons for selection. Visual representations are omitted for simplicity but can be added as figures if needed.

\subsection{Global Technical Architecture}

\graphicspath{{./}}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{evidi-complete-architecture.png}
    \caption{Global architecture}
    \label{fig:placeholder}
\end{figure}

\subsection{Module 1 — Backend API (FastAPI)}

\subsubsection*{Purpose}
The Backend API is responsible for managing all server-side logic, data persistence, user authentication, and communication between the frontend, the database, and the AI workflow engine (n8n). It acts as the central orchestrator of the Evidi architecture.

\subsubsection*{Functionality}
\begin{itemize}
    \item Provides RESTful endpoints for job offers, user criteria, summaries, and authentication.
    \item Validates and processes all data received from the frontend.
    \item Interacts with MongoDB Atlas to store and retrieve structured job and user data.
    \item Receives data from n8n workflows (job ingestion, summarization, AI matching).
    \item Ensures secure JWT-based authentication to safeguard user sessions.
\end{itemize}

\subsubsection*{Location of Source Code}
\begin{itemize}
    \item Stored in the \texttt{/backend/} directory of the project repository.
    \item Deployed automatically through Vercel's serverless backend environment.
\end{itemize}

\subsubsection*{Class and Component Structure}
\begin{itemize}
    \item \textbf{main.py} — Initializes the FastAPI application and registers all routers.
    \item \textbf{routers/auth.py} — Handles login, registration, and password recovery.
    \item \textbf{routers/jobs.py} — Exposes CRUD operations for job offers.
    \item \textbf{routers/criteria.py} — Manages user-defined filtering rules.
    \item \textbf{database/mongo.py} — Defines the MongoDB connection client.
    \item \textbf{models/\*.py} — Defines Pydantic models for validation and consistency.
\end{itemize}

\subsubsection*{Origin and Rationale}
FastAPI was chosen because:
\begin{itemize}
    \item It offers high performance through asynchronous execution.
    \item It integrates seamlessly with Pydantic for type-safe data models.
    \item Its auto-generated Swagger/OpenAPI documentation accelerates development.
    \item It fits well with serverless deployment on Vercel.
\end{itemize}

\subsubsection*{Graphical Representation (Description)}
\begin{itemize}
    \item The module sits at the center of the system architecture.
    \item Communicates upstream with the frontend, downstream with MongoDB, and laterally with n8n.
\end{itemize}


\subsection{Module 2 — Automation Workflows (n8n)}

\subsubsection*{Purpose}
This module automates the ingestion, transformation, filtering, and AI-based enrichment of job offers. It serves as the intelligence pipeline that feeds the backend with structured and enriched job information.

\subsubsection*{Functionality}
\begin{itemize}
    \item Fetches job offers from external sources (RSS, APIs, email inbox).
    \item Normalizes raw job data into a common JSON structure.
    \item Extracts job requirements and skills using AI prompts.
    \item Sends summarized job descriptions and match scores to the backend API.
    \item Schedules repeated workflows (e.g., every 2 hours).
\end{itemize}

\subsubsection*{Location of Workflow Files}
\begin{itemize}
    \item Stored and executed directly within the n8n cloud workspace.
    \item Exportable as JSON files to the project repository under \texttt{/workflows/}.
\end{itemize}

\subsubsection*{Component Breakdown}
\begin{itemize}
    \item \textbf{HTTP Request Nodes} — Retrieve job postings from external APIs.
    \item \textbf{RSS Nodes} — Subscribe to job boards and periodic updates.
    \item \textbf{Email Parsing Nodes (IMAP)} — Extract content from newsletters.
    \item \textbf{Transform Nodes} — Map and clean scraped fields.
    \item \textbf{OpenAI/Gemini Nodes} — Perform match scoring, text summarization, and cover letter generation.
    \item \textbf{Webhook / API Nodes} — Push structured data into the FastAPI backend.
\end{itemize}

\subsubsection*{Origin and Rationale}
n8n was chosen because:
\begin{itemize}
    \item It provides a no-code/low-code environment suited for rapid workflow construction.
    \item It supports integration with virtually any API via native nodes.
    \item It drastically simplifies automation processes that would otherwise require extensive backend coding.
    \item It can run fully in the cloud, enabling fast deployment on Railway.
\end{itemize}

\subsubsection*{Graphical Representation (Description)}
\begin{itemize}
    \item The workflows form a directed graph: \textit{Data Source → Transformation → AI Processing → Backend API}.
    \item The system repeats this flow periodically to keep job data up to date.
\end{itemize}

\subsection{React Frontend}

\subsubsection*{Purpose}
The React Frontend provides the user interface for interacting with the Evidi platform. Its purpose is to deliver a fast, responsive, and intuitive user experience while communicating with the backend API and presenting AI-processed job data clearly and efficiently.

\subsubsection*{Functionality}
\begin{itemize}
    \item Displays job offers, summaries, match scores, and user-filtered results.
    \item Provides forms for user authentication, criteria creation, and job exploration.
    \item Sends requests to the FastAPI backend and renders returned data dynamically.
    \item Manages user session state through JWT tokens stored securely.
    \item Handles loading states, error feedback, pagination, and UI transitions.
\end{itemize}

\subsubsection*{Location of Source Code}
\begin{itemize}
    \item Entirely stored in the \texttt{/frontend/} directory.
    \item Deployed on Vercel for seamless CI/CD and automatic static optimization.
\end{itemize}

\subsubsection*{Component and Class Structure}
\begin{itemize}
    \item \textbf{App.tsx} — Root component, router setup, global layout.
    \item \textbf{pages/\*.tsx} — Page-level components (Dashboard, Login, Job Details).
    \item \textbf{components/\*.tsx} — Reusable UI elements such as cards, modals, lists, and filters.
    \item \textbf{services/api.ts} — API wrapper for communicating with backend endpoints.
    \item \textbf{context/AuthContext.tsx} — Handles authentication state and token persistence.
    \item \textbf{utils/\*.ts} — Helper methods for formatting, parsing, and error handling.
\end{itemize}

\subsubsection*{Origin and Rationale}
React with TypeScript was selected because:
\begin{itemize}
    \item It provides a component-based architecture ideal for scalable UI development.
    \item TypeScript ensures type safety, reducing runtime errors.
    \item Strong ecosystem support (hooks, libraries, Next.js-style patterns).
    \item Perfect compatibility with Vercel hosting and CI/CD automation.
\end{itemize}

\subsubsection*{Graphical Representation (Description)}
\begin{itemize}
    \item The frontend communicates exclusively with the FastAPI backend via HTTPS.
    \item Data flows from the backend to the UI components, which update reactively.
    \item Authentication context wraps the app and controls route access.
\end{itemize}


\end{document}